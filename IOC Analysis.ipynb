{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IOC Analysis Notebook\n",
    "\n",
    "## Objective\n",
    "This Jupyter notebook is designed to perform Indicators of Compromise (IOC) analysis using various tools from the `msticpy` package. The notebook facilitates the identification and analysis of potential threats in a cybersecurity context.\n",
    "\n",
    "## Requirements\n",
    "- **Python 3.6+**\n",
    "- **Jupyter Notebook**\n",
    "\n",
    "## Modules Used\n",
    "- **msticpy**: A package providing tools for threat intelligence, security monitoring, and incident investigation.\n",
    "- **IPython.display**: For displaying rich content within the notebook.\n",
    "- **Pathlib**: For file path manipulations.\n",
    "- **pyvis**: For creating network visualizations.\n",
    "\n",
    "## How to Run the Notebook\n",
    "1. **Install the necessary modules**:  \n",
    "    Run the following command to install required Python packages:\n",
    "    ```bash\n",
    "    pip install msticpy pyvis python-whois\n",
    "    ```\n",
    "2. **Open the notebook**:  \n",
    "    Use Jupyter Notebook to open `IOC Analysis.ipynb`.\n",
    "\n",
    "3. **Execute the cells**:  \n",
    "    Run each cell sequentially to perform IOC analysis.\n",
    "\n",
    "## Important Notes\n",
    "- Ensure you have appropriate access to data environments like Azure Sentinel for querying threat intelligence data.\n",
    "- Modify the data environment configuration as per your setup.\n",
    "\n",
    "## Conclusion\n",
    "This notebook is a powerful tool for analyzing and responding to security incidents by leveraging MSTICPy's robust feature set.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Import necessary modules and tools for IOC analysis\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the nbinit module from msticpy.nbtools\n",
    "from msticpy.nbtools import nbinit\n",
    "\n",
    "# Import Path from pathlib for file path operations\n",
    "from pathlib import Path\n",
    "\n",
    "# Import display, HTML, and Image from IPython.display for displaying HTML content and images in the notebook\n",
    "from IPython.display import display, HTML, Image\n",
    "\n",
    "# Define a list of additional imports needed for the notebook\n",
    "extra_imports = [\n",
    "    \"msticpy.vis.timeseries, display_timeseries_anomolies\",  # Import display_timeseries_anomolies from msticpy.vis.timeseries\n",
    "    \"msticpy.analysis.timeseries, timeseries_anomalies_stl\",  # Import timeseries_anomalies_stl from msticpy.analysis.timeseries\n",
    "    \"datetime, datetime\",  # Import datetime from datetime module\n",
    "    \"msticpy.vis.nbdisplay, draw_alert_entity_graph\",  # Import draw_alert_entity_graph from msticpy.vis.nbdisplay\n",
    "    \"msticpy.context.ip_utils, convert_to_ip_entities\",  # Import convert_to_ip_entities from msticpy.context.ip_utils\n",
    "    \"msticpy.vis.ti_browser, browse_results\",  # Import browse_results from msticpy.vis.ti_browser\n",
    "    \"IPython.display, Image\",  # Import Image from IPython.display\n",
    "    \"msticpy.context.ip_utils, get_whois_info\",  # Import get_whois_info from msticpy.context.ip_utils\n",
    "    \"msticpy.context.ip_utils, get_ip_type\"  # Import get_ip_type from msticpy.context.ip_utils\n",
    "]\n",
    "\n",
    "# Define the required Python version\n",
    "REQ_PYTHON_VER = (3, 6)\n",
    "\n",
    "# Define the required MSTICpy version\n",
    "REQ_MSTICPY_VER = (1, 0, 0)\n",
    "\n",
    "# Define an HTML message to display if nb_check.py needs to be updated\n",
    "update_nbcheck = (\n",
    "    \"<p style='color: orange; text-align=left'>\"\n",
    "    \"<b>Warning: we needed to update '<i>utils/nb_check.py</i>'</b><br>\"\n",
    "    \"Please restart the kernel and re-run this cell.\"\n",
    "    \"</p>\"\n",
    ")\n",
    "\n",
    "# Display a message indicating the start of the notebook setup\n",
    "display(HTML(\"<h3>Starting Notebook setup...</h3>\"))\n",
    "\n",
    "# Check if the nb_check.py file exists in the utils directory\n",
    "if Path(\"./utils/nb_check.py\").is_file():\n",
    "    try:\n",
    "        # Try to import the check_versions function from nb_check.py\n",
    "        from utils.nb_check import check_versions\n",
    "    except ImportError as err:\n",
    "        # If import fails, set exception mode to minimal and download the latest nb_check.py\n",
    "        %xmode Minimal\n",
    "        !curl https://raw.githubusercontent.com/Azure/Azure-Sentinel-Notebooks/master/utils/nb_check.py > ./utils/nb_check.py 2>/dev/null\n",
    "        # Display the update message\n",
    "        display(HTML(update_nbcheck))\n",
    "    # Check if check_versions is not in the global namespace\n",
    "    if \"check_versions\" not in globals():\n",
    "        # Raise an ImportError if the old version of nb_check.py is detected\n",
    "        raise ImportError(\"Old version of nb_check.py detected - see instructions below.\")\n",
    "    # Set exception mode to verbose and check the versions\n",
    "    %xmode Verbose\n",
    "    check_versions(REQ_PYTHON_VER, REQ_MSTICPY_VER)\n",
    "\n",
    "# If not using Azure Notebooks, install msticpy with pip\n",
    "# !pip install msticpy\n",
    "\n",
    "# Define additional imports for the notebook\n",
    "extra_imports = [\n",
    "    \"msticpy.nbtools, observationlist\",  # Import observationlist from msticpy.nbtools\n",
    "    \"msticpy.sectools, domain_utils\",  # Import domain_utils from msticpy.sectools\n",
    "    \"pyvis.network, Network\",  # Import Network from pyvis.network\n",
    "]\n",
    "\n",
    "# Initialize the notebook with nbinit, passing the global namespace, additional packages, and extra imports\n",
    "nbinit.init_notebook(\n",
    "    namespace=globals(),\n",
    "    additional_packages=[\"pyvis\", \"python-whois\"],\n",
    "    extra_imports=extra_imports,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize data environments and list them for selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List available data environments using QueryProvider\n",
    "data_environments = QueryProvider.list_data_environments()\n",
    "\n",
    "# Print a message indicating the data provider\n",
    "printme(\"Data provider\")\n",
    "\n",
    "# Print the list of data environments\n",
    "print(data_environments)\n",
    "\n",
    "# Initialize a QueryProvider for the 'AzureSentinel' data environment\n",
    "qry_prov = QueryProvider(data_environment='AzureSentinel')\n",
    "\n",
    "# List available workspaces using WorkspaceConfig\n",
    "_customers = WorkspaceConfig.list_workspaces()\n",
    "\n",
    "# Initialize a SetQuery object\n",
    "Set = SetQuery()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "widget,search_q_times,search_origin= Set[0],Set[1],Set[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_customer  = [w.description for w in widget.children[1].children if w.value]\n",
    "printme(f'Selected Tenant : {selected_customer} Time : {search_origin}' ) \n",
    "\n",
    "def multi_customers(query,*args):\n",
    "    Results = []\n",
    "    # Iterate over selected customers\n",
    "    for cus in selected_customer:\n",
    "        # Connect to the customer's workspace\n",
    "        qry_prov.connect(WorkspaceConfig(workspace= cus))\n",
    "        \n",
    "        # Check if the query function is in the arguments\n",
    "        if qry_prov.exec_query in args:\n",
    "            # Execute the query function with the query string\n",
    "            Result = args[0](f'{query}')\n",
    "        # Check if only one argument is provided or no arguments are provided\n",
    "        elif len(args) == 1 or len(args) <1 :\n",
    "            # Execute the query function with the query string\n",
    "            Result = args[0](f'{query}')\n",
    "        else:\n",
    "            # Execute the query function with the query string and additional arguments\n",
    "            Result =  args[0](f'{query}',args[1])\n",
    "        \n",
    "        # Append the result to the list of results\n",
    "        Results.append(Result)\n",
    "    \n",
    "    return Results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an instance of TILookup class\n",
    "tilookup = TILookup()\n",
    "\n",
    "# Reload the providers for TILookup\n",
    "tilookup.reload_providers()\n",
    "\n",
    "# Check the status of the providers\n",
    "tilookup.provider_status\n",
    "\n",
    "# Create a text input widget for the domain or URL\n",
    "domain_url = widgets.Text(description='Please enter the domain or URL to investigate:',\n",
    "                          **WIDGET_DEFAULTS)\n",
    "\n",
    "# Display the domain or URL input widget\n",
    "display(domain_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tldextract\n",
    "from msticpy.sectools.tiproviders.ti_provider_base import TISeverity\n",
    "\n",
    "graph_items = []\n",
    "dom_val = domain_utils.DomainValidator()\n",
    "summary = observationlist.Observations()\n",
    "dom_record = None\n",
    "url=domain_url.value.strip().lower()\n",
    "\n",
    "# Extract the domain and top-level domain (TLD) using tldextract\n",
    "_, domain, tld = tldextract.extract(domain_url.value)\n",
    "domain = domain.lower() + \".\" + tld.lower()\n",
    "\n",
    "# Validate the TLD of the domain\n",
    "if dom_val.validate_tld(domain) is not True:\n",
    "    md(f\"{domain} is not a valid domain name\", \"bold\")\n",
    "\n",
    "# Check if the URL is different from the domain\n",
    "if url != domain:\n",
    "    md(f\"<strong>Domain</strong> : {domain}\")\n",
    "    md(f\"<strong>URL</strong> : {url}\")\n",
    "    graph_items.append((domain,url))\n",
    "else:\n",
    "    md(f\"<strong>Domain</strong> : {domain}\")\n",
    "    url = None\n",
    "\n",
    "# Function to convert severity to TISeverity enum\n",
    "def conv_severity(severity):\n",
    "    try:\n",
    "        if isinstance(severity, TISeverity):\n",
    "            return severity\n",
    "        if isinstance(severity, str):\n",
    "            return TISeverity[severity]\n",
    "        else:\n",
    "            return TISeverity(severity)\n",
    "    except (ValueError, KeyError):\n",
    "        return TISeverity.information\n",
    "\n",
    "# Function to check if severity meets threshold\n",
    "def ti_check_sev(severity, threshold):\n",
    "    severity = conv_severity(severity)\n",
    "    threshold = conv_severity(threshold)\n",
    "    return severity.value >= threshold.value\n",
    "\n",
    "# Lookup Threat Intelligence for the domain\n",
    "domain_ti = tilookup.result_to_df(tilookup.lookup_ioc(observable=domain, ioc_type='dns'))\n",
    "\n",
    "# If URL is provided, lookup Threat Intelligence for the URL as well\n",
    "if url is not None:\n",
    "    url_ti = tilookup.result_to_df(tilookup.lookup_ioc(observable=url, ioc_type='url'))\n",
    "    md(f\"Threat Intelligence Results for {url}\", \"bold\")\n",
    "    display(url_ti.T)\n",
    "    summary.add_observation(caption=\"URL TI\", description=f\"Summary of TI for {url}\", data=url_ti)\n",
    "    graph_items += [((url,provider)) for provider in url_ti.index\n",
    "                    if ti_check_sev(url_ti.loc[provider]['Severity'], 1)] \n",
    "\n",
    "md(f\"Threat Intelligence Results for {domain}\", \"bold\")\n",
    "display(domain_ti.T)\n",
    "summary.add_observation(caption=\"Domain TI\", description=f\"Summary of TI for {domain}\", data=domain_ti)\n",
    "graph_items += [((domain,provider)) for provider in domain_ti.index \n",
    "                if ti_check_sev(domain_ti.loc[provider]['Severity'],1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from whois import whois\n",
    "from collections import Counter\n",
    "\n",
    "# Function to calculate entropy\n",
    "def Entropy(data):\n",
    "    s, lens = Counter(data), np.float(len(data))\n",
    "    return -sum(count/lens * np.log2(count/lens) for count in s.values())\n",
    "\n",
    "# Get a whois record for our domain\n",
    "wis = whois(domain)\n",
    "\n",
    "if wis.domain_name is not None:\n",
    "    # Create domain record from whois data\n",
    "    dom_record = pd.DataFrame({\"Domain\":[domain],\n",
    "                               \"Name\":[wis['name']],\n",
    "                               \"Org\":[wis['org']],\n",
    "                               \"DNSSec\":[wis['dnssec']],\n",
    "                               \"City\":[wis['city']],\n",
    "                               \"State\":[wis['state']],\n",
    "                               \"Country\":[wis['country']],\n",
    "                               \"Registrar\": [wis['registrar']],\n",
    "                               \"Status\": [wis['status']],\n",
    "                               \"Created\":[wis['creation_date']],\n",
    "                               \"Expiration\" : [wis['expiration_date']],\n",
    "                               \"Last Updated\" : [wis['updated_date']],\n",
    "                               \"Name Servers\": [wis['name_servers']]})\n",
    "    ns_domains = []\n",
    "    \n",
    "    # Remove duplicate Name Server records\n",
    "    for server in wis['name_servers']:\n",
    "        ns_sub_d, ns_domain, ns_tld = tldextract.extract(server)\n",
    "        ns_dom = ns_domain.lower() + \".\" + ns_tld.lower()\n",
    "        if domain not in ns_domains:\n",
    "            ns_domains.append(ns_dom)                                            \n",
    "\n",
    "    # Identity domains popularity with Open Page Rank\n",
    "    page_rank = tilookup.result_to_df(tilookup.lookup_ioc(observable=domain, providers=[\"OPR\"]))\n",
    "    if page_rank['RawResult'][0]:\n",
    "        page_rank_score = page_rank['RawResult'][0]['response'][0]['page_rank_integer']\n",
    "    else:\n",
    "        page_rank_score = 0\n",
    "    dom_record[\"Page Rank\"] = [page_rank_score]\n",
    "\n",
    "    # Get a list of subdomains for the domain\n",
    "    url_ti = tilookup.result_to_df(tilookup.lookup_ioc(observable=domain, providers=[\"VirusTotal\"]))\n",
    "    if url_ti['RawResult'][0]:\n",
    "        sub_doms = url_ti['RawResult'][0]['subdomains']\n",
    "    else:\n",
    "        sub_doms = 0\n",
    "    graph_items.append((domain, \"Sub Domains\"))\n",
    "    graph_items += [(sub,\"Sub Domains\") for sub in sub_doms]\n",
    "    dom_record['Sub Domains'] = [sub_doms]\n",
    "\n",
    "    # Work out domain entropy to identify possible DGA\n",
    "    dom_ent = Entropy(domain)\n",
    "    dom_record['Domains Entropy'] = [dom_ent]\n",
    "\n",
    "    # Add elements to graph for later plotting\n",
    "    if isinstance(dom_record['Created'],list):                                                        \n",
    "        graph_items.append((domain,dom_record['Created'][0][0]))\n",
    "    else:\n",
    "        graph_items.append((domain,dom_record['Created'][0]))\n",
    "    graph_items.append((domain, \"Name Servers\"))\n",
    "    graph_items += [((\"Name Servers\", ns)) for ns in dom_record['Name Servers'][0]]\n",
    "    graph_items += [(domain,dom_record['Registrar'][0]), (domain,dom_record['Country'][0]),(domain,f\"Page Rank : {dom_record['Page Rank'][0]}\")]\n",
    "\n",
    "    # Highlight domains with low PageRank score or if their entropy is more than 2 standard deviations from the average for the top 1 million domains\n",
    "    def color_cells(val):\n",
    "        if isinstance(val, int):\n",
    "            color = 'yellow' if val < 3 else 'white'\n",
    "        elif isinstance(val, float):\n",
    "            color = 'yellow' if val > 4.30891 or val < 2.72120  else 'white'\n",
    "        else:\n",
    "            color = 'white'\n",
    "        return 'background-color: %s' % color\n",
    "\n",
    "    # Display whois details and highlight interesting values\n",
    "    display(dom_record.T.style.applymap(color_cells, subset=pd.IndexSlice[['Page Rank', 'Domains Entropy'],0]))\n",
    "    summary.add_observation(caption=\"Domain Summary\", description=f\"Summary of public domain records for {domain}\", data=dom_record)\n",
    "    md(\"If Page Rank or Domain Entropy are highlighted, this indicates that their values are outside the expected values of a legitimate website\")\n",
    "    md(f\"The average entropy for the 1M most popular domains is 3.2675\")\n",
    "\n",
    "else:\n",
    "    # If there is no whois data, see what we can use from TI\n",
    "    url_ti = tilookup.result_to_df(tilookup.lookup_ioc(observable=domain, providers=[\"VirusTotal\"]))\n",
    "    md(f\"No current whois record exists for {domain}. Below are historical records\")\n",
    "    print(url_ti['RawResult'][0]['whois'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_ti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if url is not None:\n",
    "    scope = url\n",
    "else:\n",
    "    scope = domain\n",
    "\n",
    "# See if TLS cert is in abuse.ch malicious certs list and get cert details\n",
    "result, x509 = dom_val.in_abuse_list(scope)\n",
    "\n",
    "if x509 is not None:\n",
    "    # Create a dataframe to store the certificate details\n",
    "    cert_df = pd.DataFrame({\"SN\" :[x509.serial_number],\n",
    "                            \"Subject\":[[(i.value) for i in x509.subject]],\n",
    "                            \"Issuer\": [[(i.value) for i in x509.issuer]],\n",
    "                            \"Expired\": [x509.not_valid_after],\n",
    "                            \"InAbuseList\": result})\n",
    "\n",
    "    # Display the certificate details\n",
    "    display(cert_df.T)\n",
    "    summary.add_observation(caption=\"TLS Summary\", description=f\"Summary of TLS certificate for {domain}\", data=cert_df)\n",
    "    md(\"If 'InAbuseList' is True this shows that the SSL certificate fingerprint appeared in the abuse.ch list\")\n",
    "    graph_items.append((domain,result))\n",
    "\n",
    "else:\n",
    "    md(\"No TLS certificate was found in abuse.ch lists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dns.resolver import NXDOMAIN\n",
    "from ipwhois import IPWhois\n",
    "\n",
    "import dns.resolver\n",
    "\n",
    "# Get the list of primary providers\n",
    "primary_providers = [prov[0] for prov in tilookup._providers.items()]\n",
    "\n",
    "# Add \"VirusTotal\" as a primary provider if it is loaded\n",
    "if \"VirusTotal\" in tilookup.loaded_providers and \"VirusTotal\" not in primary_providers:\n",
    "    primary_providers.append(\"VirusTotal\")\n",
    "\n",
    "# Check if the domain is resolvable\n",
    "if dom_val.is_resolvable(domain) is True:\n",
    "    try:\n",
    "        # Query the A record for the domain\n",
    "        answer = dns.resolver.query(domain, 'A')\n",
    "    except NXDOMAIN:\n",
    "        raise ValueError(\"Could not resolve IP addresses from domain.\")\n",
    "\n",
    "    # Get the first IP address from the answer\n",
    "    x = answer[0].to_text()\n",
    "\n",
    "    # Perform IPWhois lookup for the IP address\n",
    "    whois = IPWhois(x)\n",
    "    ipwis = whois.lookup_whois()\n",
    "\n",
    "    # Create a dataframe to store the IP address details\n",
    "    ip_rec = pd.DataFrame({\"IP Address\": [x],\n",
    "                           \"ASN\" : [ipwis['asn']],\n",
    "                           \"ASN Owner\": [ipwis['asn_description']],\n",
    "                           \"Country\" : [ipwis['asn_country_code']],\n",
    "                           \"Date\": [ipwis['asn_date']]})\n",
    "\n",
    "    # Add IP address and ASN details to the graph items\n",
    "    ip_addresses = ip_rec['IP Address'].to_list()\n",
    "    graph_items += [\n",
    "        (ip_rec[\"IP Address\"][0],domain),\n",
    "        (ip_rec[\"IP Address\"][0],ip_rec[\"ASN\"][0]),\n",
    "        (ip_rec[\"ASN Owner\"][0],ip_rec[\"ASN\"][0]),\n",
    "        (ip_rec[\"Country\"][0],ip_rec[\"ASN\"][0])\n",
    "    ]\n",
    "\n",
    "    # Check if the IP address is a Tor node\n",
    "    tor = None\n",
    "    if \"Tor\" in tilookup.loaded_providers:\n",
    "        tor = tilookup.result_to_df(tilookup.lookup_ioc(observable=ip_rec['IP Address'][0], providers=[\"Tor\"]))\n",
    "    if tor is None or tor['Details'][0] == \"Not found.\":\n",
    "        ip_rec['Tor Node?'] = \"No\"\n",
    "    else:\n",
    "        ip_rec['Tor Node?'] = \"Yes\"\n",
    "        graph_items.append((ip_rec[\"IP Address\"][0],\"Tor Node\"))\n",
    "\n",
    "    # Lookup Threat Intelligence for the IP address\n",
    "    ip_ti = tilookup.result_to_df(tilookup.lookup_ioc(observable=ip_rec['IP Address'][0], providers=primary_providers))\n",
    "\n",
    "    # Get the last 10 resolutions for the IP address from VirusTotal\n",
    "    last_10 = []\n",
    "    if \"VirusTotal\" in tilookup.loaded_providers:\n",
    "        last_10 = ip_ti.T['VirusTotal']['RawResult'][\"resolutions\"][0:10]\n",
    "\n",
    "    # Add previous domains to the graph items\n",
    "    prev_domains = []\n",
    "    for record in last_10:\n",
    "        prev_domains.append(record['hostname'])\n",
    "        graph_items.append((record['hostname'],ip_rec[\"IP Address\"][0]))\n",
    "\n",
    "    # Add the last 10 resolutions to the IP record\n",
    "    ip_rec[\"Last 10 resolutions\"] = [prev_domains]\n",
    "\n",
    "    # Display the IP address details\n",
    "    display(ip_rec.T)\n",
    "    summary.add_observation(caption=\"IP Summary\", description=f\"Summary of IP associated with {domain}\", data=ip_rec)\n",
    "else:\n",
    "    # If the domain is not resolvable, lookup Threat Intelligence for the IP address\n",
    "    ip_ti = tilookup.result_to_df(tilookup.lookup_ioc(observable=answer[0].to_text()))\n",
    "    print(ip_ti.T['VirusTotal']['RawResult'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if url is not None:\n",
    "    image_data = domain_utils.screenshot(url)\n",
    "else:\n",
    "    image_data = domain_utils.screenshot(domain)\n",
    "    \n",
    "with open('screenshot.png', 'wb') as f:\n",
    "        f.write(image_data.content)\n",
    "\n",
    "display(Image(filename='screenshot.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create graph from items saved to graph_items\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "G=nx.Graph()\n",
    "for item in graph_items:\n",
    "    G.add_edge(item[0],str(item[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot Graph with pyvis\n",
    "net=Network(height=900, width=900, notebook=True)\n",
    "net.barnes_hut()\n",
    "net.from_nx(G)\n",
    "net.set_options(\"\"\"\n",
    "var options = {\"nodes\": {\"color\": {\"highlight\": {\"border\": \"rgba(233,77,49,1)\"},\"hover\": {\"border\": \"rgba(233,77,49,1)\"}},\n",
    "    \"scaling\": {\"min\": 1},\"size\": 7},\n",
    "    \"edges\": {\"color\": {\"inherit\": true}, \"smooth\": false},\n",
    "    \"interaction\": {\"hover\": true,\"multiselect\": true},\n",
    "    \"manipulation\": {\"enabled\": true},\n",
    "    \"physics\": {\"enabled\": false,\"barnesHut\": {\"gravitationalConstant\": -80000,\"springLength\": 250,\"springConstant\": 0.001},\"minVelocity\": 0.75}\n",
    "}\"\"\")\n",
    "net.show(\"graph.html\")\n",
    "# If the intereactive graph does not display correcrtly uncomment the three lines below to access display a non-interactive version\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(3,figsize=(12,12))\n",
    "nx.draw(G, with_labels=True, font_weight='bold')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if the domain record exists and if the Page Rank score is less than 6\n",
    "if dom_record is None or int(dom_record[\"Page Rank\"]) < 6:\n",
    "    warning = None\n",
    "    md(f\"The Page Rank score for {domain} is low, querying for this domain should not present issues.\")\n",
    "else:\n",
    "    md_warn(f\"{domain} has a high Page Rank score, it is likely to be highly prevalent in the environment.\")\n",
    "    md(\"Please confirm below that you wish to proceed, note that some queries are likely to be slow due to large amounts of data\", \"bold\")\n",
    "    warning = widgets.Checkbox(\n",
    "        value=False,\n",
    "        description='Are you sure?',\n",
    "        disabled=False\n",
    "    )\n",
    "    display(warning)\n",
    "\n",
    "# Establish if we want to investigate just the URL or domain and URL\n",
    "if warning is not None and warning.value == False:\n",
    "    md_warn(\"Please check the box above to confirm you wish to proceed\")\n",
    "else:\n",
    "    if url is not None:\n",
    "        md(\"Do you wish to search on the URL alone or URL and Domain? For malicious URLs on known good domains you may wish to only search on the URL to get more granular results.\")\n",
    "        scope_selection = widgets.RadioButtons(\n",
    "            options=['URL Only', 'URL and Domain'],\n",
    "            disabled=False\n",
    "        )\n",
    "        display(scope_selection)\n",
    "    else:\n",
    "        scope_selection = None\n",
    "        md(f\"Searching data for {domain}\")\n",
    "        \n",
    "host_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if scope_selection is not None:\n",
    "    if scope_selection.value == \"URL Only\":\n",
    "        scope = url\n",
    "    else:\n",
    "        scope = f\"{domain}|{url}\"\n",
    "else:\n",
    "    scope = domain\n",
    "\n",
    "query_times = nbwidgets.QueryTime(units='day',\n",
    "                                      max_before=20, max_after=1, before=3)\n",
    "query_times.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get any alerts associated with the domain or URL\n",
    "alerts = qry_prov.SecurityAlert.list_alerts(\n",
    "    query_times)\n",
    "\n",
    "# Check if alerts exist and if they are related to the scope\n",
    "if isinstance(alerts, pd.DataFrame) and not alerts.empty:\n",
    "    related_alerts = alerts[alerts[\"Entities\"].str.contains(scope)]\n",
    "else:\n",
    "    alerts = None\n",
    "    display(HTML(\"No alerts found\"))\n",
    "\n",
    "# Check if related alerts exist and display them\n",
    "if isinstance(related_alerts, pd.DataFrame) and not related_alerts.empty:\n",
    "    # Count the number of alerts for each alert type\n",
    "    related_alerts_items = (related_alerts[['AlertName', 'TimeGenerated']]\n",
    "                            .groupby('AlertName').TimeGenerated.agg('count').to_dict())\n",
    "\n",
    "    def print_related_alerts(alertDict, entityType, entityName):\n",
    "        if len(alertDict) > 0:\n",
    "            display(Markdown(\n",
    "                f\"### Found {len(alertDict)} different alert types related to this {entityType} (\\'{entityName}\\')\"))\n",
    "            for (k, v) in alertDict.items():\n",
    "                display(Markdown(f\"- {k}, Count of alerts: {v}\"))\n",
    "        else:\n",
    "            display(\n",
    "                Markdown(f\"No alerts for {entityType} entity \\'{entityName}\\'\"))\n",
    "\n",
    "    # Display the related alerts\n",
    "    print_related_alerts(related_alerts_items, 'domain', domain)\n",
    "\n",
    "    # Display alerts on timeline to aid in visual grouping\n",
    "    nbdisplay.display_timeline(\n",
    "        data=related_alerts, source_columns=[\"AlertName\"], title=\"Host alerts over time\", height=300, color=\"red\")\n",
    "\n",
    "    # Calculate the score based on the number of related alerts\n",
    "    score = len(related_alerts.index) / 2\n",
    "\n",
    "    # Add the alerts to the summary\n",
    "    summary.add_observation(caption=\"Alerts\", description=f\"Alerts linked to {scope}\", data=related_alerts, score=score)\n",
    "else:\n",
    "    md(\"No related alerts found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "host_log_query = f\"\"\"\n",
    " Syslog \n",
    " | where TimeGenerated >= datetime({query_times.start}) \n",
    " | where TimeGenerated <= datetime({query_times.end})\n",
    " | where SyslogMessage matches regex \"{scope}\"\n",
    " | union isfuzzy = true (\n",
    " SecurityEvent\n",
    " | where TimeGenerated >= datetime({query_times.start}) \n",
    " | where TimeGenerated <= datetime({query_times.end})\n",
    " | where CommandLine matches regex \"{scope}\")\n",
    "\"\"\"\n",
    "# Identify any hosts with logs relating to this URL or domain and provide a summary of those hosts\n",
    "host_logs_df = qry_prov.exec_query(host_log_query)\n",
    "if not host_logs_df.empty:\n",
    "    md(f\"Summary of logs containing {scope} by host:\", \"bold\")\n",
    "    host_log_sum = pd.DataFrame({'Log Count' : host_logs_df.groupby(['Computer']).count()['TimeGenerated']}).reset_index()\n",
    "    display(host_log_sum.style.hide_index())\n",
    "    #Add details to a summary for later use\n",
    "    summary.add_observation(caption=\"Host Log Summary\", description=f\"Summary of logs containing {scope} by host\", data=host_log_sum)\n",
    "    ioc_extractor = iocextract.IoCExtract()\n",
    "    print('Extracting IPs, Domains and URLs from logs.......')\n",
    "    ioc_df = ioc_extractor.extract(data=host_logs_df,\n",
    "                                    columns=['SyslogMessage', 'CommandLine'],\n",
    "                                    os_family='Linux',\n",
    "                                    ioc_types=['ipv4', 'ipv6', 'dns', 'url'])\n",
    "    md(\"Network artifacts found in logs:\", \"bold\")\n",
    "    display(ioc_df.drop('SourceIndex', axis=1).style.hide_index())\n",
    "    # Collect a list of ip addresses associated with the domain or url\n",
    "    ip_addresses += [(ip) for ip in ioc_df[ioc_df['IoCType'] == \"ipv4\"]['Observable'] if ip not in ip_addresses]\n",
    "\n",
    "else:\n",
    "    md(f\"No host logs found containing {domain} or {url}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the logs associated with the domain or URL for each host\n",
    "def view_logs(host):\n",
    "    display(host_logs_df.query('Computer == @host'))\n",
    "\n",
    "if not host_logs_df.empty:\n",
    "    items = host_log_sum['Computer'].dropna().unique().tolist()\n",
    "    host_list = items\n",
    "    md(f\"<h3>View all host logs that contains {scope}</h3>\")\n",
    "    log_view = widgets.Dropdown(\n",
    "        options=items, description='Select Computer to view raw logs', disabled=False, **WIDGET_DEFAULTS)\n",
    "    display(widgets.interactive(view_logs, host=log_view))\n",
    "else:\n",
    "    md(f\"No host logs found containing {domain} or {url}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
